{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\alexa\\OneDrive\\Dokumente\\GitHub\\DL-GRN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Change the working directory to the location where your data files are stored\n",
    "os.chdir('../../')  # Replace with the actual path\n",
    "\n",
    "# Verify the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Load the counts data\n",
    "file_path = 'Data/RAW/raw_count_matrix/raw_count_matrix2.txt'\n",
    "counts_df = pd.read_csv(file_path, delimiter='\\t')\n",
    "counts_df = counts_df.set_index('Gene')\n",
    "\n",
    "# Replace hyphens with dots in the column names of the counts DataFrame\n",
    "counts_df.columns = counts_df.columns.str.replace(\"-\", \".\")\n",
    "\n",
    "# Transpose the counts DataFrame to align conditions as row indices\n",
    "counts_df_t = counts_df.transpose()\n",
    "\n",
    "# Load the metadata\n",
    "file_path = 'Data/RAW/metadata.txt'\n",
    "metadata_df = pd.read_csv(file_path, delimiter='\\t')\n",
    "metadata_df.columns = ['Sample', 'Treatment', 'Time']\n",
    "metadata_df = metadata_df.set_index('Sample')\n",
    "\n",
    "# Merge the transposed counts DataFrame with the metadata DataFrame based on the condition identifiers\n",
    "merged_df = counts_df_t.merge(metadata_df, left_index=True, right_index=True)\n",
    "\n",
    "# Find the maximum count for each gene across all time points and samples per condition\n",
    "max_counts_per_condition = merged_df.groupby('Treatment').max()\n",
    "\n",
    "# Transpose back to the original format\n",
    "result_df = max_counts_per_condition.transpose()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABA\n",
      "     16470\n",
      "0     8681\n",
      "1     8390\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "ABA + MeJA\n",
      "     16600\n",
      "0     8555\n",
      "1     8386\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "MeJA\n",
      "     16536\n",
      "0     8616\n",
      "1     8389\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Mock\n",
      "     16723\n",
      "0     8431\n",
      "1     8387\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "SA\n",
      "     16738\n",
      "0     8417\n",
      "1     8386\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "SA + MeJA\n",
      "     16652\n",
      "0     8502\n",
      "1     8387\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Number of rows with a mix of 0s and 1s: 0\n"
     ]
    }
   ],
   "source": [
    "# Log10 transform the values (adding 1 to each count to handle zeros)\n",
    "log10_transformed_df = np.log10(result_df + 1)\n",
    "\n",
    "# Save the transformed data to a new CSV file if needed\n",
    "log10_transformed_df.to_csv('Data/Processed/log10_transformed_max_counts_per_condition.csv')\n",
    "\n",
    "# Create a new DataFrame to store gene names and count levels\n",
    "count_levels = pd.DataFrame(index=log10_transformed_df.index)\n",
    "\n",
    "# Determine the quartiles for each condition and label the genes\n",
    "for condition in log10_transformed_df.columns:\n",
    "    data = log10_transformed_df[condition]\n",
    "    \n",
    "    # Calculate quartiles\n",
    "    q1 = data.quantile(0.25)\n",
    "    q3 = data.quantile(0.75)\n",
    "    \n",
    "    # Label the genes based on quartile ranges\n",
    "    count_levels[condition] = np.where(data <= q1, 0, \n",
    "                                       np.where(data >= q3, 1, ''))\n",
    "\n",
    "# Combine the count levels into a single column\n",
    "#count_levels['count_level'] = count_levels.apply(lambda row: '0' if 'low' in row.values else ('0' if 'high' in row.values else ''), axis=1)\n",
    "\n",
    "# Filter out genes that are in the middle quartile (empty count_level)\n",
    "#final_count_levels = count_levels[count_levels['count_level'] != '']\n",
    "\n",
    "# Keep only the gene names and the final count_level\n",
    "#final_count_levels = final_count_levels[['count_level']]\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "\n",
    "count_levels.to_csv('Data/Processed/gene_count_levels.csv')\n",
    "\n",
    "#sanity check\n",
    "for condition in count_levels.columns:\n",
    "    print(count_levels[condition].value_counts())\n",
    "    print('\\n')\n",
    "\n",
    "# How often are genes in different count levels across conditions?\n",
    "def has_mix_of_0s_and_1s(row):\n",
    "    unique_values = set(row.dropna().values)\n",
    "    return 0 in unique_values and 1 in unique_values\n",
    "\n",
    "# Apply the function to each row and count occurrences\n",
    "mix_count = count_levels.apply(has_mix_of_0s_and_1s, axis=1).sum()\n",
    "\n",
    "# Output the count\n",
    "print(f\"Number of rows with a mix of 0s and 1s: {mix_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
